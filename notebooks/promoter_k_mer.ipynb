{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "sbgYQg1_KPls",
        "xaPz5Gx613OS",
        "G1MotUib15EL"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PromoterMotifFinder\n",
        "\n",
        "This program identifies the most common DNA sequence motifs within the promoter regions of a given list of genes. It extracts upstream promoter sequences (typically a fixed length upstream of the transcription start site) from a reference genome and search motifs (with JASPAR database)\n",
        "\n",
        "Each motif is then counted based on the number of occurrences across all input gene regions. Finally, the motifs are ranked and listed according to their frequency, reflecting how often each motif appears within the gene set.\n",
        "\n",
        "Similar to FIMO, but easy to use.\n",
        "\n",
        "## Further reading\n",
        " - Known Motif Scanning: Begin by scanning your defined promoter regions for known TFBSs using established databases like JASPAR and [TRANSFAC](https://genexplain.com/transfac-product/) (via tools like [FIMO](https://meme-suite.org/meme/tools/fimo) or TRANSFAC Match). This provides immediate hypotheses about potential regulatory TFs.\n",
        " - Motif Enrichment Analysis: Follow up by performing motif enrichment analysis (e.g., with TRANSFAC FMatch or [HOMER](http://homer.ucsd.edu/homer/homer2.html)) to statistically identify which of these known motifs are significantly overrepresented in your gene set compared to the background. This pinpoints the most probable common regulating TFs.\n",
        "\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "M4WBgVr9-Z-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Set parameters and `Runtime` -> `Run all`\n",
        "from google.colab import files\n",
        "import os\n",
        "import re\n",
        "import hashlib\n",
        "import random\n",
        "import glob\n",
        "\n",
        "from sys import version_info\n",
        "python_version = f\"{version_info.major}.{version_info.minor}\"\n",
        "\n",
        "def add_hash(x,y):\n",
        "  return x+\"_\"+hashlib.sha1(y.encode()).hexdigest()[:5]\n",
        "\n",
        "SPECIES = \"Killifish\" #@param {type:\"string\"} [\"C.elegans\", \"Killifish\"]\n",
        "#@markdown - Promoter size to search.\n",
        "PROMOTER_LENGTH = 2000 #@param {type:\"raw\"}\n",
        "#@markdown - motif match threshold.\n",
        "PWM_SCORE_THRESHOLD = 0.9 # @param {type:\"slider\", min:0.7, max:1, step:0.1}\n",
        "#@markdown - List of interested genes (WBid/ENSEMBLGENE). must be this format \"[\"Gene1\", \"Gene2\"...]\"\n",
        "GENES_OF_INTEREST = [\"ENSNFUG00015001047\", \"ENSNFUG00015001509\", \"ENSNFUG00015003068\", \"ENSNFUG00015006014\", \"ENSNFUG00015006496\", \"ENSNFUG00015007030\", \"ENSNFUG00015008382\", \"ENSNFUG00015009619\", \"ENSNFUG00015010807\", \"ENSNFUG00015011287\", \"ENSNFUG00015011653\", \"ENSNFUG00015012125\", \"ENSNFUG00015012302\", \"ENSNFUG00015012412\", \"ENSNFUG00015017059\", \"ENSNFUG00015018034\", \"ENSNFUG00015019527\", \"ENSNFUG00015020785\", \"ENSNFUG00015020981\", \"ENSNFUG00015022868\", \"ENSNFUG00015023747\", \"ENSNFUG00015024112\", \"ENSNFUG00015024297\", \"ENSNFUG00015025252\", \"ENSNFUG00015025346\", \"ENSNFUG00015020771\", \"ENSNFUG00015012024\"] #@param {type:\"raw\"}\n",
        "\n",
        "jaspar_taxid = {\"C.elegans\": 6239,\n",
        "                \"Killifish\": 8078,\n",
        "                \"Mouse\": 10090}\n",
        "\n",
        "jaspar_taxgrp = {\"C.elegans\": \"Nematodes\",\n",
        "                \"Killifish\": \"Vertebrates\",\n",
        "                \"Mouse\": \"Vertebrates\",\n",
        "\n",
        "}\n",
        "genome_wget_addr = {\"C.elegans\": \"1H6cAsIMS2wH2Wh8bii8N4n9sVie-unFv\",\n",
        "                    \"Killifish\": \"1lEMBw8I_41gplugWgJh-9uS9_BDCVtMW\",\n",
        "                    \"Mouse\": \"1mAjaSJG21jKFlQBt2qYlDKLDTTrBE6I6\",\n",
        "                    }\n",
        "gtf_wget_addr = {\"C.elegans\": \"1hitCMc-VVyscVvkfe0QCDz5nKTGHyxnA\",\n",
        "                \"Killifish\": \"16TbToIZQFmcTxsgP__ZBr3fdykG5CJl0\",\n",
        "                 \"Mouse\": \"1fzKgOW6fHWb2lY-OOSZ0k-r1fnsGCpqd\",\n",
        "                 }\n",
        "jaspar_wget_addr = {\"C.elegans\": \"1d0Po7ed-Eq6Mm9NLu4paRGH4ZMK0WlQU\",\n",
        "                \"Killifish\": \"1OEy3MePEhZ9DtdyzuFwtFQo5G11bVRsc\",\n",
        "                 \"Mouse\": \"1OEy3MePEhZ9DtdyzuFwtFQo5G11bVRsc\",\n",
        "                }\n",
        "\n",
        "background_files = {\n",
        "    \"C.elegans\": \"1D0hb2uYuK9kepcQfTriGeSLQoJT6LyOc\",\n",
        "    \"Killifish\": \"14gGqQfZpEoPVT1BX9xLFz2OL9FE1WvjT\",\n",
        "}\n",
        "\n",
        "target_taxid = jaspar_taxgrp[SPECIES]\n",
        "GENOME_WGET = genome_wget_addr[SPECIES]\n",
        "GTF_WGET = gtf_wget_addr[SPECIES]\n",
        "JASPAR_WGET = jaspar_wget_addr[SPECIES]\n",
        "BGDIST_WGET = background_files[SPECIES]\n",
        "\n",
        "GeneIDheader = {\"C.elegans\": \"WB\",\n",
        "                \"Killifish\": \"ENSNFUG\",\n",
        "                \"Mouse\": \"ENSMUSG\"}\n",
        "\n",
        "for x in GENES_OF_INTEREST:\n",
        "    assert GeneIDheader[SPECIES] in x, \"Check your gene list again\""
      ],
      "metadata": {
        "id": "HW-Jamc93xmO",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run"
      ],
      "metadata": {
        "id": "KLFDP-QN6GEV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up"
      ],
      "metadata": {
        "id": "sbgYQg1_KPls"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwb8Ne0dgacb"
      },
      "outputs": [],
      "source": [
        "pip install biopython"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import requests\n",
        "import math\n",
        "import dill, pickle, os\n",
        "from collections import defaultdict, Counter\n",
        "from Bio import SeqIO # You'll need Biopython installed (pip install biopython)\n",
        "from Bio import motifs\n",
        "from Bio.Seq import Seq\n",
        "from statsmodels.stats.multitest import fdrcorrection\n",
        "from scipy.stats import fisher_exact\n",
        "import tqdm\n",
        "import datetime\n",
        "import pytz\n",
        "import pandas as pd\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "6_kNP4sLsTmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Configuration ---\n",
        "GENOME_FASTA_GZ = \"/content/genome.fa.gz\"\n",
        "REFSEQ_GTF_GZ = \"/content/gtf.gz\"\n",
        "\n",
        "GENOME_FASTA = \"/content/genome.fa\"\n",
        "REFSEQ_GTF = \"/content/gtf\"\n",
        "JASPAR_PFM_FILE = \"/content/jaspar\"\n",
        "BG_FILE = \"/content/bg_killifish.tar.gz\"\n",
        "\n",
        "!gdown $GENOME_WGET -O $GENOME_FASTA_GZ\n",
        "!sleep 2\n",
        "!gunzip -f $GENOME_FASTA_GZ\n",
        "!sleep 2\n",
        "\n",
        "!gdown $GTF_WGET -O $REFSEQ_GTF_GZ\n",
        "!sleep 2\n",
        "!gunzip -f $REFSEQ_GTF_GZ\n",
        "!sleep 2\n",
        "\n",
        "!gdown $JASPAR_WGET -O $JASPAR_PFM_FILE\n",
        "!sleep 2\n",
        "\n",
        "!gdown $BGDIST_WGET\n",
        "!tar -xf $BG_FILE"
      ],
      "metadata": {
        "id": "k2qSqE3zvywx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## src"
      ],
      "metadata": {
        "id": "xaPz5Gx613OS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_pseudocounts(motif):\n",
        "    \"\"\"Calculate pseudocounts.\n",
        "\n",
        "    Computes the root square of the total number of sequences multiplied by\n",
        "    the background nucleotide.\n",
        "    \"\"\"\n",
        "    alphabet = motif.alphabet\n",
        "    background = motif.background\n",
        "\n",
        "    # It is possible to have unequal column sums so use the average\n",
        "    # number of instances.\n",
        "    total = 0\n",
        "    for i in range(motif.length):\n",
        "        total += sum(motif.counts[letter][i] for letter in alphabet)\n",
        "\n",
        "    avg_nb_instances = total / motif.length\n",
        "    sq_nb_instances = math.sqrt(avg_nb_instances)\n",
        "\n",
        "    if background:\n",
        "        background = dict(background)\n",
        "    else:\n",
        "        background = dict.fromkeys(sorted(alphabet), 1.0)\n",
        "\n",
        "    total = sum(background.values())\n",
        "    pseudocounts = {}\n",
        "\n",
        "    for letter in alphabet:\n",
        "        background[letter] /= total\n",
        "        pseudocounts[letter] = sq_nb_instances * background[letter]\n",
        "\n",
        "    return pseudocounts\n",
        "\n",
        "\n",
        "# --- 1. Load Genome ---\n",
        "def load_genome(fasta_file):\n",
        "    \"\"\"\n",
        "    Loads the genome sequence from a FASTA file into a dictionary.\n",
        "    Keys are chromosome names, values are SeqIO objects.\n",
        "    \"\"\"\n",
        "    print(f\"Loading genome from {fasta_file}...\")\n",
        "    genome = SeqIO.to_dict(SeqIO.parse(fasta_file, \"fasta\"))\n",
        "    print(\"Genome loaded.\")\n",
        "    return genome\n",
        "\n",
        "\n",
        "# --- 2. Parse Gene Annotations and Get Promoter Coordinates ---\n",
        "def get_promoter_coordinates(gtf_file, genes_of_interest, promoter_length):\n",
        "    \"\"\"\n",
        "    Parses a GTF/GFF file to get gene coordinates and calculate promoter regions.\n",
        "    Returns a dictionary: {gene_id: {'chr': str, 'start': int, 'end': int, 'strand': str}}\n",
        "    Note: This is a simplified parser. Real GTF/GFF parsing can be complex.\n",
        "    \"\"\"\n",
        "    print(f\"Parsing annotations from {gtf_file} and identifying promoter regions...\")\n",
        "    gene_promoters = {}\n",
        "    with open(gtf_file, 'r') as f:\n",
        "        for line in f:\n",
        "            if line.startswith('#'):\n",
        "                continue\n",
        "            parts = line.strip().split('\\t')\n",
        "            # Assuming GTF/GFF format: seqname source feature start end score strand frame attributes\n",
        "            seqname = parts[0]\n",
        "            feature_type = parts[2]\n",
        "            start = int(parts[3])\n",
        "            end = int(parts[4])\n",
        "            strand = parts[6]\n",
        "            attributes = parts[8]\n",
        "\n",
        "            if feature_type == \"gene\": # Or \"CDS\" depending on what you define as gene start\n",
        "                # Extract gene ID from attributes (this part is highly dependent on GTF/GFF format)\n",
        "                # Example for Ensembl GTF: gene_id \"WBGene0000001\"; gene_version \"1\";\n",
        "                #gene_id_match = [attr.strip().split(' ')[1].strip('\"') for attr in attributes.split(';') if \"gene_id\" in attr]\n",
        "                gene_id_match = attributes.split(';')[0].replace('gene_id ','').replace('\"','')\n",
        "                if not gene_id_match:\n",
        "                    continue\n",
        "                gene_id = gene_id_match\n",
        "\n",
        "                if genes_of_interest and gene_id not in genes_of_interest:\n",
        "                    continue\n",
        "\n",
        "                promoter_start = -1\n",
        "                promoter_end = -1\n",
        "\n",
        "                if strand == '+':\n",
        "                    # Promoter is upstream of the start site\n",
        "                    promoter_start = start - promoter_length\n",
        "                    promoter_end = start - 1 # Or just 'start' if you want to include the TSS base\n",
        "                elif strand == '-':\n",
        "                    # Promoter is upstream of the end site (for reverse strand)\n",
        "                    promoter_start = end + 1 # Or just 'end'\n",
        "                    promoter_end = end + promoter_length\n",
        "\n",
        "                # Ensure promoter coordinates are not negative\n",
        "                promoter_start = max(0, promoter_start)\n",
        "\n",
        "                if promoter_start != -1 and promoter_end != -1:\n",
        "                    gene_promoters[gene_id] = {\n",
        "                        'chr': seqname,\n",
        "                        'start': promoter_start,\n",
        "                        'end': promoter_end,\n",
        "                        'strand': strand\n",
        "                    }\n",
        "    print(f\"Found promoter regions for {len(gene_promoters)} genes.\")\n",
        "    return gene_promoters\n",
        "\n",
        "\n",
        "# --- 3. Extract Promoter Sequences ---\n",
        "def extract_promoter_sequences(genome, gene_promoters):\n",
        "    \"\"\"\n",
        "    Extracts the DNA sequence for each promoter region.\n",
        "    Returns a dictionary: {gene_id: 'sequence'}\n",
        "    \"\"\"\n",
        "    print(\"Extracting promoter sequences...\")\n",
        "    promoter_sequences = {}\n",
        "    for gene_id, coords in gene_promoters.items():\n",
        "        chrom = coords['chr']\n",
        "        start = coords['start']\n",
        "        end = coords['end']\n",
        "        strand = coords['strand']\n",
        "\n",
        "        if chrom not in genome:\n",
        "            print(f\"Warning: Chromosome '{chrom}' not found in genome for gene {gene_id}. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        # Biopython Seq objects are 0-indexed, slice is [start:end]\n",
        "        # Adjusting for 1-based GTF to 0-based Python slicing\n",
        "        seq_obj = genome[chrom].seq[start:end]\n",
        "\n",
        "        if strand == '-':\n",
        "            seq_obj = seq_obj.reverse_complement()\n",
        "        promoter_sequences[gene_id] = str(seq_obj).upper() # Convert to string and uppercase\n",
        "    print(f\"Extracted sequences for {len(promoter_sequences)} promoters.\")\n",
        "    return promoter_sequences\n",
        "\n",
        "\n",
        "# --- Revised Common K-mer to Known Motif Comparison (using PFM/PWM scanning) ---\n",
        "def compare_common_kmers_with_pfms(common_kmers, jaspar_motifs, promoter_sequences, score_threshold):\n",
        "    \"\"\"\n",
        "    Compares found common k-mers by scanning promoter regions with JASPAR PWMs.\n",
        "    This is a more robust way to link found k-mers to known motifs.\n",
        "    It identifies which promoter regions contain matches to known motifs.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Scanning promoter regions for known JASPAR motifs (score threshold: {score_threshold*100:.1f}%) ---\")\n",
        "    motif_hits_in_promoters = defaultdict(lambda: defaultdict(list)) # {motif_name: {gene_id: [(pos, score, seq, strand), ...]}}\n",
        "    overall_motif_counts = defaultdict(int) # {motif_name: total occurrences}\n",
        "\n",
        "    for motif_name, motif_obj in jaspar_motifs.items():\n",
        "        print(f\"Scanning for motif: {motif_name} (Length: {len(motif_obj)})\")\n",
        "        for gene_id, promoter_seq in promoter_sequences.items():\n",
        "            # Ensure promoter sequence is long enough to contain the motif\n",
        "            if len(promoter_seq) >= len(motif_obj):\n",
        "                matches = scan_sequence_with_pwm(promoter_seq, motif_obj, score_threshold)\n",
        "                if matches:\n",
        "                    motif_hits_in_promoters[motif_name][gene_id].extend(matches)\n",
        "                    overall_motif_counts[motif_name] += len(matches)\n",
        "\n",
        "    print(\"\\n--- Summary of Known Motif Hits in Promoters ---\")\n",
        "    if overall_motif_counts:\n",
        "        for motif_name, count in sorted(overall_motif_counts.items(), key=lambda item: item[1], reverse=True):\n",
        "            continue#print(f\"Motif: {motif_name} (Total hits: {count})\")\n",
        "            # You can uncomment to print individual hits:\n",
        "            # for gene_id, hits in motif_hits_in_promoters[motif_name].items():\n",
        "            #     for pos, score, seq, strand in hits:\n",
        "            #         print(f\"  Gene {gene_id}: Match '{seq}' at position {pos} (strand {strand}, score {score:.2f})\")\n",
        "    else:\n",
        "        print(\"No known motifs found in promoter regions with the given threshold.\")\n",
        "\n",
        "    # You could also link your *found k-mers* directly to the motifs\n",
        "    # by checking if your exact k-mers (from common_kmers) achieve a high score\n",
        "    # against the PWMs, but the primary use of PWMs is to scan a sequence.\n",
        "    # For now, we'll just report the found motif occurrences.\n",
        "    return motif_hits_in_promoters\n",
        "\n",
        "\n",
        "# --- scan_sequence_with_pwm (The latest corrected version with .min_score()/.max_score())\n",
        "def scan_sequence_with_pwm(sequence, motif_obj, threshold_percent):\n",
        "    \"\"\"\n",
        "    Scans a DNA sequence for matches to a motif using its PWM/PSSM.\n",
        "    Returns a list of (start_position, score, matching_sequence) tuples\n",
        "    for matches exceeding the threshold, considering both strands.\n",
        "    \"\"\"\n",
        "    matches = []\n",
        "\n",
        "    pssm = motif_obj.pssm\n",
        "\n",
        "    min_score = pssm.min\n",
        "    max_score = pssm.max\n",
        "\n",
        "    if (max_score - min_score) > 0:\n",
        "        score_cutoff = (max_score - min_score) * threshold_percent + min_score\n",
        "    else:\n",
        "        # print(f\"Warning: Motif '{motif_obj.name}' has min_score == max_score. Skipping scanning.\", file=sys.stderr)\n",
        "        return [] # Return empty if no valid score range\n",
        "\n",
        "    # Scan forward strand\n",
        "    for position, score in pssm.search(str(sequence), threshold=score_cutoff):\n",
        "        if position + len(motif_obj) <= len(sequence):\n",
        "            matched_seq = sequence[position : position + len(motif_obj)]\n",
        "            matches.append((position, score, matched_seq, '+'))\n",
        "\n",
        "    # Scan reverse complement strand\n",
        "    rev_comp_sequence_obj = Seq(sequence).reverse_complement()\n",
        "    rev_comp_sequence_str = str(rev_comp_sequence_obj)\n",
        "\n",
        "    for position, score in pssm.search(rev_comp_sequence_str, threshold=score_cutoff):\n",
        "        if position + len(motif_obj) <= len(rev_comp_sequence_str):\n",
        "            matched_seq = rev_comp_sequence_str[position : position + len(motif_obj)]\n",
        "            matches.append((position, score, matched_seq, '-'))\n",
        "\n",
        "    return matches\n",
        "\n",
        "\n",
        "def scan_for_hits(promoter_seqs, jaspar_motifs):\n",
        "    \"\"\"Helper function to scan a set of promoters and return motif hits.\"\"\"\n",
        "    motif_hits = defaultdict(lambda: {'count': 0, 'genes': set()})\n",
        "    for motif_name, motif_obj in tqdm.tqdm(jaspar_motifs.items()):\n",
        "        if not motif_obj or len(motif_obj) == 0:\n",
        "            continue\n",
        "        try:\n",
        "            _ = motif_obj.pssm\n",
        "        except Exception as e:\n",
        "            continue # Already warned in parsing step\n",
        "\n",
        "        for gene_id, promoter_seq in promoter_seqs.items():\n",
        "            if len(promoter_seq) >= len(motif_obj):\n",
        "                matches = scan_sequence_with_pwm(promoter_seq, motif_obj, PWM_SCORE_THRESHOLD)\n",
        "                if matches:\n",
        "                    motif_hits[motif_name]['count'] += len(matches)\n",
        "                    motif_hits[motif_name]['genes'].add(gene_id)\n",
        "    return motif_hits\n",
        "\n",
        "\n",
        "def load_jaspar_pfm(file_path):\n",
        "    \"\"\"\n",
        "    Parses a JASPAR-like PFM file with a custom floating-point format.\n",
        "    Assumes 4 rows (A, C, G, T) for each motif.\n",
        "    Converts float counts to integers by rounding for Bio.motifs.Motif object.\n",
        "    Crucially, passes PSSM_PSEUDOCOUNTS to the Motif constructor.\n",
        "    \"\"\"\n",
        "    print(f\"Starting custom parsing of PFM file: {file_path}\")\n",
        "    jaspar_motifs = {}\n",
        "\n",
        "    current_motif_name = None\n",
        "    current_pfm_rows = [] # Will temporarily store [A_counts, C_counts, G_counts, T_counts]\n",
        "\n",
        "    try:\n",
        "        with open(file_path, \"r\") as f:\n",
        "            for line_num, line in enumerate(f, 1):\n",
        "                original_line = line # Keep original for error messages\n",
        "                line = line.strip()\n",
        "\n",
        "                if not line: # Skip empty lines\n",
        "                    continue\n",
        "\n",
        "                if line.startswith('>'):\n",
        "                    # A new motif is starting. First, try to process the previous one.\n",
        "                    if current_motif_name: # Check if there was a previous motif being built\n",
        "                        if len(current_pfm_rows) == 4:\n",
        "                            try:\n",
        "                                integer_pfm_dict = {\n",
        "                                    'A': [int(round(x)) for x in current_pfm_rows[0]],\n",
        "                                    'C': [int(round(x)) for x in current_pfm_rows[1]],\n",
        "                                    'G': [int(round(x)) for x in current_pfm_rows[2]],\n",
        "                                    'T': [int(round(x)) for x in current_pfm_rows[3]],\n",
        "                                }\n",
        "\n",
        "                                # Check if any row is empty (e.g., due to parsing errors resulting in empty lists)\n",
        "                                if any(not row for row in integer_pfm_dict.values()):\n",
        "                                    raise ValueError(\"One or more PFM rows are empty after conversion.\")\n",
        "\n",
        "                                # THE FIX HERE: Pass pseudocounts to the Motif constructor\n",
        "                                motif_obj = motifs.Motif(alphabet=\"ACGT\", counts=integer_pfm_dict)\n",
        "                                motif_obj.pseudocounts = calculate_pseudocounts(motif_obj)\n",
        "\n",
        "                                motif_obj.name = current_motif_name\n",
        "                                jaspar_motifs[current_motif_name] = motif_obj\n",
        "                                # print(f\"Successfully parsed motif: {current_motif_name}\") # Debugging line\n",
        "                            except Exception as e:\n",
        "                                print(f\"Error processing motif '{current_motif_name}' (started around line {line_num - len(current_pfm_rows) -1}): Incomplete or malformed data preventing motif creation: {e}\", file=sys.stderr)\n",
        "                        else:\n",
        "                            print(f\"Warning: Motif '{current_motif_name}' (started around line {line_num - len(current_pfm_rows) -1}) has {len(current_pfm_rows)} data rows instead of 4. Skipping.\", file=sys.stderr)\n",
        "\n",
        "                    # Reset for the new motif\n",
        "                    parts = line[1:].split(' ')\n",
        "                    if len(parts) > 1:\n",
        "                        current_motif_name = parts[1]\n",
        "                    else:\n",
        "                        current_motif_name = parts[0]\n",
        "                    current_pfm_rows = [] # Clear rows for the new motif\n",
        "                    # print(f\"Detected new motif header: {current_motif_name}\") # Debugging line\n",
        "\n",
        "                else:\n",
        "                    # This is a data line (A, C, G, T counts)\n",
        "                    if current_motif_name is None:\n",
        "                        print(f\"Warning: Data line found before any motif header at line {line_num}: '{original_line.strip()}'. Skipping.\", file=sys.stderr)\n",
        "                        continue\n",
        "\n",
        "                    if len(current_pfm_rows) >= 4:\n",
        "                        print(f\"Warning: Motif '{current_motif_name}' at line {line_num}: More than 4 data rows detected. Skipping extra row: '{original_line.strip()}'.\", file=sys.stderr)\n",
        "                        continue\n",
        "\n",
        "                    try:\n",
        "                        counts = [float(x) for x in line.split()]\n",
        "                        # Essential check: ensure 'counts' list is not empty after splitting\n",
        "                        if not counts:\n",
        "                            print(f\"Warning: Motif '{current_motif_name}' at line {line_num}: Data line is empty after splitting. Skipping: '{original_line.strip()}'.\", file=sys.stderr)\n",
        "                            continue\n",
        "\n",
        "                        current_pfm_rows.append(counts)\n",
        "                    except ValueError as e:\n",
        "                        print(f\"Error parsing data line for motif '{current_motif_name}' at line {line_num}: '{original_line.strip()}'. Error: {e}. Skipping this line.\", file=sys.stderr)\n",
        "\n",
        "        # After the loop, process the very last motif in the file\n",
        "        if current_motif_name: # Check if there was any motif at all\n",
        "            if len(current_pfm_rows) == 4:\n",
        "                try:\n",
        "                    integer_pfm_dict = {\n",
        "                        'A': [int(round(x)) for x in current_pfm_rows[0]],\n",
        "                        'C': [int(round(x)) for x in current_pfm_rows[1]],\n",
        "                        'G': [int(round(x)) for x in current_pfm_rows[2]],\n",
        "                        'T': [int(round(x)) for x in current_pfm_rows[3]],\n",
        "                    }\n",
        "                    if any(not row for row in integer_pfm_dict.values()):\n",
        "                        raise ValueError(\"One or more PFM rows are empty after conversion in final motif.\")\n",
        "\n",
        "                    # THE FIX HERE: Pass pseudocounts to the Motif constructor for the last motif\n",
        "                    motif_obj = motifs.Motif(alphabet=\"ACGT\", counts=integer_pfm_dict)\n",
        "                    motif_obj.pseudocounts = calculate_pseudocounts(motif_obj)\n",
        "\n",
        "                    motif_obj.name = current_motif_name\n",
        "                    jaspar_motifs[current_motif_name] = motif_obj\n",
        "                    # print(f\"Successfully parsed final motif: {current_motif_name}\") # Debugging line\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing final motif '{current_motif_name}': Incomplete or malformed data preventing motif creation: {e}\", file=sys.stderr)\n",
        "            else:\n",
        "                print(f\"Warning: Final motif '{current_motif_name}' has {len(current_pfm_rows)} data rows instead of 4. Skipping.\", file=sys.stderr)\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Critical Error: PFM file not found at {file_path}\", file=sys.stderr)\n",
        "        return {} # Return empty dict on critical file error\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected critical error occurred during file reading: {e}\", file=sys.stderr)\n",
        "        return {} # Return empty dict on critical file error\n",
        "\n",
        "    print(f\"Finished custom PFM parsing. Loaded {len(jaspar_motifs)} motifs.\")\n",
        "    return jaspar_motifs"
      ],
      "metadata": {
        "id": "Abf-a1GTga2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## main"
      ],
      "metadata": {
        "id": "G1MotUib15EL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Load Genome ---\n",
        "genome_data = load_genome(GENOME_FASTA)\n",
        "if not genome_data:\n",
        "    print(\"Error: Genome data could not be loaded. Exiting.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# --- 2. Load JASPAR Motifs ---\n",
        "jaspar_motifs_obj = load_jaspar_pfm(JASPAR_PFM_FILE)\n",
        "if not jaspar_motifs_obj:\n",
        "    print(\"Error: No JASPAR motifs loaded from the PFM file. Check file path and format. Exiting.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# --- 3. Get Promoter Coordinates for TARGET Genes ---\n",
        "print(f\"\\n--- Processing Target Genes: {len(GENES_OF_INTEREST)} genes specified ---\")\n",
        "target_promoter_coords = get_promoter_coordinates(REFSEQ_GTF, GENES_OF_INTEREST, PROMOTER_LENGTH)\n",
        "\n",
        "if not target_promoter_coords:\n",
        "    print(\"Warning: No promoter coordinates found for target genes. Cannot scan for motifs. Exiting.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "genes_to_process_target = {gene_id: coords for gene_id, coords in target_promoter_coords.items()\n",
        "                            if coords['chr'] in genome_data}\n",
        "\n",
        "if not genes_to_process_target:\n",
        "    print(\"Warning: No target genes to process after filtering by genome presence. Exiting.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# --- 4. Extract Promoter Sequences for TARGET Genes ---\n",
        "target_promoter_seqs = extract_promoter_sequences(genome_data, genes_to_process_target)\n",
        "if not target_promoter_seqs:\n",
        "    print(\"Warning: No promoter sequences could be extracted for target genes. Exiting.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# --- 5. Scan Target Promoter Regions for Known Motifs ---\n",
        "print(\"\\n--- Scanning Target Promoter Regions for Known Motifs ---\")\n",
        "target_motif_hits = defaultdict(lambda: {'count': 0, 'genes': set()}) # {motif_name: {'count': N, 'genes': {gene_ids}}}\n",
        "\n",
        "for motif_name, motif_obj in jaspar_motifs_obj.items():\n",
        "    if not motif_obj or len(motif_obj) == 0:\n",
        "        print(motif_obj)\n",
        "        continue # Skip invalid motifs\n",
        "\n",
        "    try:\n",
        "        _ = motif_obj.pssm # Test PSSM access\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Could not generate PSSM for motif '{motif_name}': {e}. Skipping.\", file=sys.stderr)\n",
        "        continue\n",
        "\n",
        "    # print(f\"Scanning for motif: {motif_name} (Length: {len(motif_obj)}) in target promoters...\")\n",
        "    for gene_id, promoter_seq in target_promoter_seqs.items():\n",
        "        if len(promoter_seq) >= len(motif_obj):\n",
        "            matches = scan_sequence_with_pwm(promoter_seq, motif_obj, PWM_SCORE_THRESHOLD)\n",
        "            if matches:\n",
        "                target_motif_hits[motif_name]['count'] += len(matches)\n",
        "                target_motif_hits[motif_name]['genes'].add(gene_id)\n",
        "        # else:\n",
        "        #     print(f\"Debug: Promoter for {gene_id} too short for motif {motif_name}. Skipping.\")\n",
        "\n",
        "print(\"\\n--- Motif Scan Results in Target Promoters ---\")\n",
        "if target_motif_hits:\n",
        "    sorted_target_hits = sorted(target_motif_hits.items(), key=lambda item: item[1]['count'], reverse=True)\n",
        "else:\n",
        "    print(\"No motifs found in target promoter regions with the given threshold.\")\n",
        "\n",
        "final = []\n",
        "for k, v in sorted_target_hits:\n",
        "    final.append({'motif': k, 'hits': v['count'], 'genes': len(v['genes']), 'gene list': v['genes']})\n",
        "\n",
        "genelist_final = pd.DataFrame().from_dict(final)\n",
        "\n",
        "target_background_path = f\"background_{SPECIES}_PWM_{PWM_SCORE_THRESHOLD}.pkl\"\n",
        "if not os.path.exists(target_background_path):\n",
        "    current_date = datetime.datetime.now().astimezone(pytz.timezone('CET'))\n",
        "    datestamp = f\"{str(current_date.year)[-2:]}{current_date.month:02d}{current_date.day:02d}_{current_date.strftime('%X').replace(':','')}\"\n",
        "    download_name = f\"motif_search_{datestamp}.csv\"\n",
        "    genelist_final.to_csv(download_name)\n",
        "    files.download(f\"{download_name}\")\n",
        "    raise('no stat test')"
      ],
      "metadata": {
        "id": "-Zc2Jdaf2F5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 6: Perform Statistical Enrichment Analysis ---\n",
        "with open(target_background_path, 'rb') as outp:\n",
        "    background_motif_hits = dill.load(outp, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "all_gene_promoter_coords = get_promoter_coordinates(REFSEQ_GTF, [], PROMOTER_LENGTH)\n",
        "\n",
        "valid_promoter_coords = {gene_id: coords for gene_id, coords in all_gene_promoter_coords.items()\n",
        "                            if coords['chr'] in genome_data}\n",
        "\n",
        "total_target_genes = len(GENES_OF_INTEREST)\n",
        "total_background_genes = len(valid_promoter_coords)\n",
        "\n",
        "enrichment_results = []\n",
        "\n",
        "for motif_name, motif_data in jaspar_motifs_obj.items():\n",
        "    if motif_name not in target_motif_hits and motif_name not in background_motif_hits:\n",
        "        continue\n",
        "\n",
        "    count_target_has_motif = len(target_motif_hits.get(motif_name, {}).get('genes', set()))\n",
        "    count_background_has_motif = len(background_motif_hits.get(motif_name, {}).get('genes', set()))\n",
        "\n",
        "    count_target_no_motif = total_target_genes - count_target_has_motif\n",
        "    count_background_no_motif = total_background_genes - count_background_has_motif\n",
        "\n",
        "    table = [[count_target_has_motif, count_background_has_motif],\n",
        "              [count_target_no_motif, count_background_no_motif]]\n",
        "\n",
        "    if any(sum(row) == 0 for row in table) or any(sum(col) == 0 for col in zip(*table)):\n",
        "        p_value = 1.0\n",
        "        odds_ratio = float('nan')\n",
        "    else:\n",
        "        odds_ratio, p_value = fisher_exact(table, alternative='greater')\n",
        "\n",
        "    enrichment_results.append({\n",
        "        'motif_name': motif_name,\n",
        "        'target_genes_with_motif': count_target_has_motif,\n",
        "        'background_genes_with_motif': count_background_has_motif,\n",
        "        'total_target_genes': total_target_genes,\n",
        "        'total_background_genes': total_background_genes,\n",
        "        'odds_ratio': odds_ratio,\n",
        "        'p_value': p_value\n",
        "    })\n",
        "\n",
        "# Perform Multiple Testing Correction (Benjamini-Hochberg FDR)\n",
        "valid_p_values = [res['p_value'] for res in enrichment_results]\n",
        "\n",
        "if valid_p_values:\n",
        "    reject, adjusted_p_values = fdrcorrection(valid_p_values, alpha=0.05, method='indep')\n",
        "\n",
        "    p_idx = 0\n",
        "    for res in enrichment_results:\n",
        "        if res['p_value'] is not None:\n",
        "            res['adjusted_p_value'] = adjusted_p_values[p_idx]\n",
        "            res['significant_fdr'] = reject[p_idx]\n",
        "            p_idx += 1\n",
        "        else:\n",
        "            res['adjusted_p_value'] = float('nan')\n",
        "            res['significant_fdr'] = False\n",
        "\n",
        "genelist_final.index = genelist_final['motif']\n",
        "er = pd.DataFrame().from_dict(enrichment_results)\n",
        "er.index = er['motif_name']\n",
        "\n",
        "stat_final = pd.concat([genelist_final['gene list'], er], axis=1)\n",
        "\n",
        "current_date = datetime.datetime.now().astimezone(pytz.timezone('CET'))\n",
        "datestamp = f\"{str(current_date.year)[-2:]}{current_date.month:02d}{current_date.day:02d}_{current_date.strftime('%X').replace(':','')}\"\n",
        "download_name = f\"motif_search_with_fdr_{datestamp}.csv\"\n",
        "pd.DataFrame().from_dict(stat_final).to_csv(download_name)\n",
        "files.download(f\"{download_name}\")"
      ],
      "metadata": {
        "id": "TrHPAOC8iDuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Note\n",
        "Vibe coding with Gemini & [Youngjun Park](https://github.com/iron-lion) (youngjun.park@age.mpg.de)"
      ],
      "metadata": {
        "id": "RhxbPC3X-56f"
      }
    }
  ]
}